# src/tests/test_integration_full.py
import pytest
import tempfile
import os
import time
from src.tiny_aria import TinyARIA
from src.cognitive_pipeline import CognitivePipeline
from src.session_manager import SessionManager

class TestFullIntegration:
    def test_complete_pipeline(self):
        """–¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        
        with tempfile.TemporaryDirectory() as temp_dir:
            # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            config = self._create_test_config(temp_dir)
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—É
            aria = TinyARIA(temp_dir)
            assert aria.initialize() == True
            
            # –°–æ–∑–¥–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω
            pipeline = CognitivePipeline(aria.layers)
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –≤–≤–æ–¥–∞
            test_inputs = [
                "–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?",
                "–ß—Ç–æ —Ç–∞–∫–æ–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç?",
                "–ü–æ–º–æ–≥–∏ –º–Ω–µ —Ä–µ—à–∏—Ç—å –∑–∞–¥–∞—á—É",
                "–Ø –≥—Ä—É—Å—Ç–Ω—ã–π —Å–µ–≥–æ–¥–Ω—è"
            ]
            
            for user_input in test_inputs:
                result = pipeline.process_input(user_input)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                assert 'response' in result
                assert 'confidence' in result
                assert 'layer_results' in result
                assert 'processing_metadata' in result
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ—Ç–≤–µ—Ç –Ω–µ –ø—É—Å—Ç–æ–π
                assert len(result['response']) > 0
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ confidence –≤ –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö –ø—Ä–µ–¥–µ–ª–∞—Ö
                assert 0.0 <= result['confidence'] <= 1.0
                
                print(f"Input: {user_input}")
                print(f"Response: {result['response']}")
                print(f"Confidence: {result['confidence']:.2f}")
                print("-" * 40)
                
    def test_session_continuity(self):
        """–¢–µ—Å—Ç –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ—Å—Ç–∏ —Å–µ—Å—Å–∏–∏"""
        
        with tempfile.TemporaryDirectory() as temp_dir:
            config = self._create_test_config(temp_dir)
            
            aria = TinyARIA(temp_dir)
            aria.initialize()
            
            pipeline = CognitivePipeline(aria.layers)
            session_manager = SessionManager()
            
            session_id = "test_session_123"
            
            # –ü–µ—Ä–≤–æ–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ
            session_context = session_manager.get_session(session_id)
            result1 = pipeline.process_input("–ú–µ–Ω—è –∑–æ–≤—É—Ç –ê–ª–µ–∫—Å–µ–π", session_context)
            
            session_manager.update_session(session_id, result1['context_updates'])
            session_manager.add_to_conversation_history(
                session_id, "–ú–µ–Ω—è –∑–æ–≤—É—Ç –ê–ª–µ–∫—Å–µ–π", result1['response']
            )
            
            # –í—Ç–æ—Ä–æ–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ
            session_context = session_manager.get_session(session_id)
            result2 = pipeline.process_input("–ö–∞–∫ –º–µ–Ω—è –∑–æ–≤—É—Ç?", session_context)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–∏—Å—Ç–µ–º–∞ –ø–æ–º–Ω–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
            assert session_context['interaction_count'] == 1
            assert len(session_context.get('conversation_history', [])) == 1
            
            print(f"First interaction: {result1['response']}")
            print(f"Second interaction: {result2['response']}")
            
    def test_memory_persistence(self):
        """–¢–µ—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–∞–º—è—Ç–∏ –º–µ–∂–¥—É —Å–µ—Å—Å–∏—è–º–∏"""
        
        with tempfile.TemporaryDirectory() as temp_dir:
            config = self._create_test_config(temp_dir)
            
            # –ü–µ—Ä–≤–∞—è —Å–µ—Å—Å–∏—è
            aria1 = TinyARIA(temp_dir)
            aria1.initialize()
            
            pipeline1 = CognitivePipeline(aria1.layers)
            result1 = pipeline1.process_input("–Ø –∏–∑—É—á–∞—é –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ Python")
            
            # –ó–∞–≤–µ—Ä—à–∞–µ–º –ø–µ—Ä–≤—É—é —Å–µ—Å—Å–∏—é
            aria1.shutdown()
            
            # –í—Ç–æ—Ä–∞—è —Å–µ—Å—Å–∏—è (–Ω–æ–≤—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä)
            aria2 = TinyARIA(temp_dir)
            aria2.initialize()
            
            pipeline2 = CognitivePipeline(aria2.layers)
            result2 = pipeline2.process_input("–ß—Ç–æ —è –∏–∑—É—á–∞—é?")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–∏–ª–∞—Å—å
            # (–í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ memory layer –¥–æ–ª–∂–µ–Ω –∑–∞–≥—Ä—É–∂–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î)
            
            aria2.shutdown()
            
    def test_error_handling(self):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫"""
        
        with tempfile.TemporaryDirectory() as temp_dir:
            config = self._create_test_config(temp_dir)
            
            aria = TinyARIA(temp_dir)
            aria.initialize()
            
            pipeline = CognitivePipeline(aria.layers)
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –≤—Ö–æ–¥—ã
            problematic_inputs = [
                "",  # –ü—É—Å—Ç–æ–π –≤–≤–æ–¥
                "x" * 10000,  # –û—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–π –≤–≤–æ–¥
                "ü§ñüëæüöÄüí´",  # –¢–æ–ª—å–∫–æ —ç–º–æ–¥–∑–∏
                "1234567890",  # –¢–æ–ª—å–∫–æ —á–∏—Å–ª–∞
            ]
            
            for user_input in problematic_inputs:
                try:
                    result = pipeline.process_input(user_input)
                    
                    # –°–∏—Å—Ç–µ–º–∞ –¥–æ–ª–∂–Ω–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –≤—Ö–æ–¥—ã –±–µ–∑ –∫—Ä–∞—à–µ–π
                    assert 'response' in result
                    assert result['confidence'] >= 0.0
                    
                    print(f"Handled problematic input: '{user_input[:20]}...'")
                    print(f"Response: {result['response'][:50]}...")
                    
                except Exception as e:
                    pytest.fail(f"System crashed on input '{user_input}': {e}")
                    
    def test_performance_benchmarks(self):
        """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã"""
        
        with tempfile.TemporaryDirectory() as temp_dir:
            config = self._create_test_config(temp_dir)
            
            aria = TinyARIA(temp_dir)
            aria.initialize()
            
            pipeline = CognitivePipeline(aria.layers)
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏
            test_input = "–ö–∞–∫–∞—è —Å–µ–≥–æ–¥–Ω—è –ø–æ–≥–æ–¥–∞?"
            
            processing_times = []
            
            for i in range(10):
                start_time = time.time()
                result = pipeline.process_input(f"{test_input} (—Ç–µ—Å—Ç {i})")
                end_time = time.time()
                
                processing_time = end_time - start_time
                processing_times.append(processing_time)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —Å–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω–∞—è
                assert processing_time < 10.0, f"Processing took too long: {processing_time:.2f}s"
                
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            avg_time = sum(processing_times) / len(processing_times)
            max_time = max(processing_times)
            min_time = min(processing_times)
            
            print(f"Performance benchmarks:")
            print(f"  Average processing time: {avg_time:.3f}s")
            print(f"  Max processing time: {max_time:.3f}s")
            print(f"  Min processing time: {min_time:.3f}s")
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–∑—É–º–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            assert avg_time < 5.0, f"Average processing time too slow: {avg_time:.3f}s"
            assert max_time < 8.0, f"Max processing time too slow: {max_time:.3f}s"
            
    def test_confidence_calibration(self):
        """–¢–µ—Å—Ç –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã"""
        
        with tempfile.TemporaryDirectory() as temp_dir:
            config = self._create_test_config(temp_dir)
            
            aria = TinyARIA(temp_dir)
            aria.initialize()
            
            pipeline = CognitivePipeline(aria.layers)
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤—Ö–æ–¥—ã —Å —Ä–∞–∑–Ω—ã–º —É—Ä–æ–≤–Ω–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
            test_cases = [
                ("–ü—Ä–∏–≤–µ—Ç", "high"),  # –ü—Ä–æ—Å—Ç–æ–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ - –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                ("–ß—Ç–æ —Ç–∞–∫–æ–µ –∫–≤–∞–Ω—Ç–æ–≤–∞—è –º–µ—Ö–∞–Ω–∏–∫–∞?", "medium"),  # –°–ª–æ–∂–Ω—ã–π –≤–æ–ø—Ä–æ—Å - —Å—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                ("asdfghjkl qwerty", "low"),  # –ë–µ—Å—Å–º—ã—Å–ª–∏—Ü–∞ - –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                ("2+2=?", "high"),  # –ü—Ä–æ—Å—Ç–∞—è –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞ - –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            ]
            
            for user_input, expected_confidence_level in test_cases:
                result = pipeline.process_input(user_input)
                confidence = result['confidence']
                
                print(f"Input: {user_input}")
                print(f"Confidence: {confidence:.3f} (expected: {expected_confidence_level})")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ–∂–∏–¥–∞–Ω–∏—è–º
                if expected_confidence_level == "high":
                    assert confidence > 0.7, f"Expected high confidence, got {confidence:.3f}"
                elif expected_confidence_level == "medium":
                    assert 0.3 < confidence <= 0.7, f"Expected medium confidence, got {confidence:.3f}"
                elif expected_confidence_level == "low":
                    assert confidence <= 0.3, f"Expected low confidence, got {confidence:.3f}"
                    
    def _create_test_config(self, temp_dir):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        
        import json
        
        config = {
            "system": {
                "debug": True
            },
            "perception": {
                "max_tokens": 500,
                "context_levels": 3
            },
            "memory": {
                "working_size": 5,
                "episodic_limit": 100,
                "episodic_memory": {
                    "db_path": os.path.join(temp_dir, "test_episodes.db")
                },
                "associations": {
                    "save_path": os.path.join(temp_dir, "test_associations.pkl")
                }
            },
            "reasoning": {
                "max_steps": 5,
                "quantum_qubits": 4
            },
            "metacognition": {
                "confidence_threshold": 0.7
            },
            "ethics": {
                "harm_threshold": 0.1
            }
        }
        
        config_file = os.path.join(temp_dir, "default.json")
        with open(config_file, 'w') as f:
            json.dump(config, f, indent=2)
            
        return config